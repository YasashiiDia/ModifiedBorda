{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RYM Interactive Poll Results.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2T8yLz4p5DOC"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXEOyvMc1KaP"
      },
      "source": [
        "# **RYM Interactive Poll Results**\n",
        "\n",
        "This notebook represents the third iteration of an idea I had when I made my first RYM poll. However, there is still a lot of room for improvement and additional features. The source code is quite lousy, but it is completely contained within this notebook and hence can be readily reviewed and modified. Please let me know if you have any suggestions!\n",
        "\n",
        "â€”YasashiiDia ([GitHub](https://github.com/YasashiiDia/ModifiedBorda))\n",
        "\n",
        "### Available Polls\n",
        "\n",
        "- **Film Board Ranks the Decades of Cinema: 2010s** (closed)\n",
        "\n",
        "  Hosted by diction ([RYM List](https://rateyourmusic.com/list/diction/rym-ranks-the-decades-of-cinema-2010s-2021_final-edition/))\n",
        "\n",
        "\n",
        "- **Film Board Ranks the Decades of Cinema: 2000s** (closed)\n",
        "\n",
        "  Hosted by Rengar18 ([RYM List](https://rateyourmusic.com/list/Rengar18/film-board-ranks-the-decades-of-cinema-2000s/))\n",
        "\n",
        "- **Film Board Ranks the Decades of Cinema: 1990s** (closed)\n",
        "\n",
        "  Hosted by Rengar18 ([RYM List](https://rateyourmusic.com/list/Rengar18/film-board-ranks-the-decades-of-cinema-1990s/))\n",
        "\n",
        "- **Film Board Ranks the Decades of Cinema: 1980s** (closed)\n",
        "\n",
        "  Hosted by Rengar18 ([RYM List](https://rateyourmusic.com/list/Rengar18/film-board-ranks-the-decades-of-cinema-1980s/))\n",
        "\n",
        "- **Top Anime Series as Voted for by RYM** (open)\n",
        "\n",
        "  Hosted by YasashiiDia ([RYM List](https://rateyourmusic.com/list/YasashiiDia/top-anime-series-as-voted-for-by-rym/))\n",
        "\n",
        "\n",
        "### **Instructions**\n",
        "\n",
        "**You need to be signed into your Google account if you want to interact with the widgets in this notebook.** You also need to accept a scary-looking prompt warning you that this notebook was not authored by Google.\n",
        "\n",
        "To run the entire notebook: **Runtime -> Run all** (easiest/recommended way to get started)\n",
        "\n",
        "To run an individual cell: Click on the run button in the top left corner of the cell\n",
        "\n",
        "To hide code: double click on the rendered area to the right of the code cell.\n",
        "\n",
        "Also, you don't have to worry about permanently \"breaking\" the notebook, the master version is stored in my Google Drive and cannot be modified by you. What you are seeing right now is an editable view of the master version. Feel free to copy this notebook to save any modifications you have made (File -> Save a Copy in Drive). You can always return to the master version by visiting [this link](https://colab.research.google.com/drive/1hOq6fSF2a7t00FXl-KBUVlYifpz9ZkHp?usp=sharing).\n",
        "\n",
        "**Regarding metadata:**\n",
        "\n",
        "The metadata (cast, crew, language, etc.) was automatically fetched from external databases such as [TMDB.org](https://www.themoviedb.org/). However, since I only have few bits of information as search queries, some of the fetched data is still missing or incorrect (mostly due to works that have similar titles). Fixing this will require manual cleanup. Anyway, film polls will be much simpler once RYM gets its own API (one can always dream...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVhxS8FiYgtu"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WystQNnOcJh-",
        "cellView": "form"
      },
      "source": [
        "#@markdown <- Run this cell to load all datasets. **This is required for any other cells to work** and may take up to 20 seconds.\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import seaborn as sns; sns.set()\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import HTML\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "\n",
        "params = {\n",
        "   'axes.labelsize': 16,\n",
        "   'font.size': 16,\n",
        "   'legend.fontsize': 16,\n",
        "   'xtick.labelsize': 14,\n",
        "   'ytick.labelsize': 14,\n",
        "   'font.family': 'sans-serif'\n",
        "   }\n",
        "plt.rcParams.update(params)\n",
        "palette = sns.color_palette()\n",
        "\n",
        "pd.set_option('max_rows', None)\n",
        "\n",
        "layout={'width': '350px'} # Widget layout\n",
        "\n",
        "###\n",
        "\n",
        "query_tmdb = False\n",
        "max_queries = 1000\n",
        "TOP_ITEMS = 100\n",
        "\n",
        "###############################################\n",
        "# Option 1: Load data from Google sheets      #\n",
        "# Option 2: Load vote matrix csvs from GitHub #\n",
        "###############################################\n",
        "\n",
        "\"\"\"\n",
        "The spreadsheet needs two subsheets, named \"Votes\", \"Titles\".\n",
        "The Votes and first two columns of the Titles sheets need to be filled by the user.\n",
        "The notebook will save the vote matrix as a csv file.\n",
        "Reference sheet: https://docs.google.com/spreadsheets/d/12QQ6aC2SsDjtlT7u5kcbFiKBAQWU0JA_rq2CEKciwTk/edit?usp=sharing\n",
        "\"\"\"\n",
        "\n",
        "options = {\"default_delimiter\": \". \",\n",
        "          \"special_delimiters\": [\"\\) \"],\n",
        "          \"load_from_sheet\": False,\n",
        "          \"size_dependent_borda\": False,\n",
        "          \"remove_original_title\": True,\n",
        "          \"database_id\": \"TMDB_id\",\n",
        "          \"finalchar\": \"]\",\n",
        "          \"link\": \"https://www.themoviedb.org/movie/\"}\n",
        "\n",
        "options_film_2010s = options.copy()\n",
        "options_film_2010s[\"dataname\"] = 'Film (2010s)'\n",
        "options_film_2010s[\"SHEETNAME\"] = '2010s Movies'\n",
        "options_film_2010s[\"vote_matrix_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/2010s%20Movies_vote_matrix.csv\"\n",
        "options_film_2010s[\"titles_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/2010s%20Movies%20-%20Titles.csv\"\n",
        "options_film_2010s[\"metacols\"] = ['Release','Runtime','Genres','Language','Cast','Director','Producer','Writer','Director of Photography','Editor','Composer','Sound Designer','Art Direction','Production Design','Costume Design','Makeup Artist']\n",
        "options_film_2010s[\"type\"] = \"Film\"\n",
        "options_film_2010s[\"DEFAULT_RANK_OPTION\"] = \"BORDA_RANK_CLASSIC\"\n",
        "options_film_2010s[\"print\"] = \"ID\"\n",
        "\n",
        "options_film_2000s = options.copy()\n",
        "options_film_2000s[\"dataname\"] = 'Film (2000s)'\n",
        "options_film_2000s[\"SHEETNAME\"] = '2000s Movies'\n",
        "options_film_2000s[\"vote_matrix_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/2000s%20Movies_vote_matrix.csv\"\n",
        "options_film_2000s[\"titles_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/2000s%20Movies%20-%20Titles.csv\"\n",
        "options_film_2000s[\"metacols\"] = ['Release','Runtime','Genres','Language','Cast','Director','Producer','Writer','Director of Photography','Editor','Composer','Sound Designer','Art Direction','Production Design','Costume Design','Makeup Artist']\n",
        "options_film_2000s[\"type\"] = \"Film\"\n",
        "options_film_2000s[\"DEFAULT_RANK_OPTION\"] = \"BORDA_RANK_CLASSIC\"\n",
        "options_film_2000s[\"print\"] = \"ID\"\n",
        "\n",
        "options_film_1990s = options.copy()\n",
        "options_film_1990s[\"dataname\"] = 'Film (1990s)'\n",
        "options_film_1990s[\"SHEETNAME\"] = '1990s in film'\n",
        "options_film_1990s[\"vote_matrix_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/1990s%20in%20film_vote_matrix.csv\"\n",
        "options_film_1990s[\"titles_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/1990s%20in%20film_meta_df.csv\"\n",
        "options_film_1990s[\"metacols\"] = ['Release','Runtime','Genres','Language','Cast','Director','Producer','Writer','Director of Photography','Editor','Composer','Sound Designer','Art Direction','Production Design','Costume Design','Makeup Artist']\n",
        "options_film_1990s[\"type\"] = \"Film\"\n",
        "options_film_1990s[\"DEFAULT_RANK_OPTION\"] = \"BORDA_RANK_CLASSIC\"\n",
        "options_film_1990s[\"print\"] = \"ID\"\n",
        "\n",
        "options_film_1980s = options.copy()\n",
        "options_film_1980s[\"dataname\"] = 'Film (1980s)'\n",
        "options_film_1980s[\"SHEETNAME\"] = '1980s in film'\n",
        "options_film_1980s[\"vote_matrix_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/1980s%20in%20film_vote_matrix.csv\"\n",
        "options_film_1980s[\"titles_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/1980s%20in%20film_meta_df.csv\"\n",
        "options_film_1980s[\"metacols\"] = ['Release','Runtime','Genres','Language','Cast','Director','Producer','Writer','Director of Photography','Editor','Composer','Sound Designer','Art Direction','Production Design','Costume Design','Makeup Artist']\n",
        "options_film_1980s[\"type\"] = \"Film\"\n",
        "options_film_1980s[\"DEFAULT_RANK_OPTION\"] = \"BORDA_RANK_CLASSIC\"\n",
        "options_film_1980s[\"print\"] = \"ID\"\n",
        "\n",
        "options_film_combined = options.copy()\n",
        "options_film_combined[\"dataname\"] = 'Film (Combined)'\n",
        "options_film_combined[\"vote_matrix_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/combined_film_vote_matrix.csv\"\n",
        "options_film_combined[\"titles_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/combined_film_metadata.csv\"\n",
        "options_film_combined[\"metacols\"] = ['Release','Runtime','Genres','Language','Cast','Director','Producer','Writer','Director of Photography','Editor','Composer','Sound Designer','Art Direction','Production Design','Costume Design','Makeup Artist']\n",
        "options_film_combined[\"type\"] = \"Film\"\n",
        "options_film_combined[\"DEFAULT_RANK_OPTION\"] = \"BORDA_RANK_CLASSIC\"\n",
        "options_film_combined[\"print\"] = \"ID\"\n",
        "\n",
        "options_anime_series = options.copy()\n",
        "options_anime_series[\"dataname\"] = 'Anime Series'\n",
        "options_anime_series[\"SHEETNAME\"] = 'RYM AniChart 4.1'\n",
        "options_anime_series[\"finalchar\"] = \"\"\n",
        "options_anime_series[\"database_id\"] = \"AniListID\"\n",
        "options_anime_series[\"link\"] = \"https://anilist.co/anime/\"\n",
        "options_anime_series[\"remove_original_title\"] = False\n",
        "options_anime_series[\"vote_matrix_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/RYM%20AniChart%204.1_vote_matrix.csv\"\n",
        "options_anime_series[\"titles_csv\"] = \"https://raw.githubusercontent.com/YasashiiDia/ModifiedBorda/main/data/RYM%20AniChart%204.1%20-%20Titles.csv\"\n",
        "options_anime_series[\"metacols\"] = ['Genres','Studio','Source','Episodes','First Air Date','Last Air Date']\n",
        "options_anime_series[\"type\"] = \"Series\"\n",
        "options_anime_series[\"DEFAULT_RANK_OPTION\"] = \"BORDA_RANK\"\n",
        "options_anime_series[\"print\"] = \"Title\"\n",
        "options_anime_series[\"size_dependent_borda\"] = True\n",
        "\n",
        "options_list = [options_film_2010s,\n",
        "               options_film_2000s,\n",
        "               options_film_1990s,\n",
        "               options_film_1980s,\n",
        "               options_film_combined,\n",
        "               options_anime_series]\n",
        "#options_list2 = [options_film_1980s]\n",
        "###############################################################\n",
        "###############################################################\n",
        "###############################################################\n",
        "\n",
        "def get_votes_df(votesheet, finalchar=\"\", **options):\n",
        "\n",
        "  votes = np.array(votesheet.get_all_values())\n",
        "  votes_df = pd.DataFrame(votes[1:,:], columns=votes[0], index=range(1,len(votes[:,0])))\n",
        "\n",
        "  # Replace non-breaking white space\n",
        "  votes_df = votes_df.replace(u'\\u00A0',' ', regex=True)\n",
        "\n",
        "  # Tag unranked votes\n",
        "  votes_df = votes_df.mask(np.char.startswith(votes_df.values.astype(str), \"[\"), \"-1. \" + votes_df)\n",
        "\n",
        "  for voter in votes_df:    \n",
        "    #remove comments after finalchar\n",
        "    if finalchar != \"\":\n",
        "      vvv = votes_df[voter].str.split(\"]\", n=1, expand=True) + \"]\"\n",
        "      votes_df[voter] = vvv[0]\n",
        "\n",
        "  # Replace non-default delimiters\n",
        "  for sd in options[\"special_delimiters\"]:\n",
        "    votes_df.replace(sd, options[\"default_delimiter\"], regex=True, inplace=True)\n",
        "\n",
        "  # Take care of whitespace inconsistencies\n",
        "  votes_df = votes_df.replace(' ','', regex=True).replace('.\\[','. [', regex=True)\n",
        "  \n",
        "  return votes_df.mask(votes_df==\"]\", \"0\")\n",
        "\n",
        "def get_vote_matrix(votes_df):\n",
        "\n",
        "  vote_matrix = pd.DataFrame()\n",
        "\n",
        "  for voter in votes_df:\n",
        "    for i, vote in enumerate(votes_df[voter]):\n",
        "      if vote == \"\": break\n",
        "      try: rank, title = vote.split(\". \", 1)\n",
        "      except ValueError: \n",
        "        rank, title = i+1, vote.split(\". \", 1)[-1]\n",
        "      title = title.lstrip()\n",
        "      vote_matrix.loc[title, voter] = rank\n",
        "\n",
        "  vote_matrix.fillna(0,inplace=True)\n",
        "  vote_matrix = vote_matrix.astype(pd.SparseDtype(\"int\", 0))\n",
        "  try: vote_matrix = vote_matrix.drop([\"0\"])\n",
        "  except KeyError: pass\n",
        "  #print('Density:', vote_matrix.sparse.density, '\\nvote_matrix.shape', vote_matrix.shape)\n",
        "  return vote_matrix\n",
        "\n",
        "def get_titles_df(metasheet):\n",
        "\n",
        "  titles_arr = np.array(metasheet.get_all_values())\n",
        "  titles_df = pd.DataFrame(titles_arr[1:,1], index=titles_arr[1:,0], columns=[\"Title\"])\n",
        "  return titles_df\n",
        "\n",
        "def get_meta_df(metasheet):\n",
        "\n",
        "  titles_arr = np.array(metasheet.get_all_values())\n",
        "  multiindex = [np.array(titles_arr[1:,0]),np.array(titles_arr[1:,1])]\n",
        "  meta_df = pd.DataFrame(titles_arr[1:,2:], index=multiindex, columns=titles_arr[0,2:])\n",
        "  meta_df.index.names = [\"ID\",\"Title\"]\n",
        "  return meta_df\n",
        "\n",
        "def get_vote_matrix_titled(vote_matrix, meta_df):\n",
        "\n",
        "  vote_matrix = vote_matrix.sort_index()\n",
        "\n",
        "  # Case 1: vote_matrix.index consists of IDs\n",
        "  meta_df = meta_df.sort_index()\n",
        "\n",
        "  if np.sum(vote_matrix.index != meta_df.index.get_level_values(\"ID\")) != 0:\n",
        "    # Case 2: vote_matrix.index consists of titles\n",
        "    meta_df = meta_df.sort_index(level=\"Title\")\n",
        "    assert np.sum(vote_matrix.index != meta_df.index.get_level_values(\"Title\")) == 0\n",
        "\n",
        "  vote_matrix.index = meta_df.index\n",
        "\n",
        "  return vote_matrix\n",
        "\n",
        "def gaussian(x, mu, sig):\n",
        "    return np.exp(-np.power(x - mu, 2.) / (2 * np.power(sig, 2.)))\n",
        "\n",
        "def superellipse(x, n=2, a=1, b=1, size=1):\n",
        "  return b * (size**n - np.abs(x/a)**n)**(1/n)\n",
        "\n",
        "def linear_pop_multiplier(counts, most_votes, pop_weight):\n",
        "\n",
        "  theta = np.linspace(-1/most_votes, 1/most_votes, 201)[pop_weight+100]\n",
        "  b = (1-theta*most_votes)/2\n",
        "  multipliers = theta * counts + b\n",
        "  return 2*multipliers\n",
        "\n",
        "def exp_pop_multiplier(counts, most_votes, pop_weight):\n",
        "\n",
        "  if pop_weight == 0: return np.ones(len(counts))\n",
        "\n",
        "  multipliers = 1 + most_votes * np.exp(-(counts-1)**2 / (2*(pop_weight*most_votes)**2))\n",
        "  multipliers /= 1 + most_votes\n",
        "  return multipliers\n",
        "\n",
        "def elliptical_pop_multiplier(counts, most_votes, pop_weight):\n",
        "\n",
        "  if pop_weight >= 0: # mirror superellipse along vertical axis\n",
        "    counts = counts + 2 * (most_votes//2 - counts) + 1 + most_votes%2\n",
        "  \n",
        "  n = np.linspace(1, 0.1, 101)[np.abs(pop_weight)]\n",
        "  multipliers = superellipse(counts-1, n=n, a=1, b=1/most_votes, size=most_votes) # counts-1 to move superellipse upwards\n",
        "  return 2*multipliers\n",
        "\n",
        "def get_results_df(vote_matrix, Weight, PopWeight, pop_multiplier, partial_rankings, size_dependent=False, norm_factors=[], cc_dict=[]):\n",
        "\n",
        "  for v in vote_matrix: vote_matrix[v] = vote_matrix[v].mask(vote_matrix[v]<0,partial_rankings[v].loc[\"Avg_Unranked_Rank\"])\n",
        "  list_sizes = partial_rankings.loc[\"Size\"] if size_dependent else max(partial_rankings.loc[\"Size\"])\n",
        "\n",
        "  results = pd.DataFrame(index=vote_matrix.index)\n",
        "  results[\"Votes\"] = vote_matrix.astype(bool).sum(axis=1)\n",
        "  MOST_VOTES = max(results[\"Votes\"])\n",
        "\n",
        "  score_matrix = vote_matrix.mask(vote_matrix>0, superellipse(vote_matrix-1,n=Weight,a=1,b=1,size=list_sizes)) # vm-1 to move superellipse upwards\n",
        "  results[\"Score\"] = score_matrix.sum(axis=1)\n",
        "\n",
        "  if len(norm_factors) > 0:\n",
        "    for cc in cc_dict:\n",
        "      id = cc_dict[cc].DEFAULT_RANK.index\n",
        "      results.loc[id, \"Score\"] *= norm_factors[cc]\n",
        "      results.loc[id, \"Votes\"] *= norm_factors[cc]\n",
        "      MOST_VOTES = max(results[\"Votes\"])\n",
        "\n",
        "  if pop_multiplier == \"vote_pop_multiplier\": results[\"Score\"] *= results[\"Votes\"]\n",
        "  else: results[\"Score\"] *= pop_multiplier(results[\"Votes\"], MOST_VOTES, PopWeight)\n",
        "\n",
        "  results[\"Score\"] = results[\"Score\"].round(1)\n",
        "  results[\"Score\"] += 0.00001*results[\"Votes\"] # hacky way of breaking ties by number of votes AND use method=\"min\" for tied votes\n",
        "  results[\"Rank\"] = results[\"Score\"].rank(ascending=False,method='min').astype(int)\n",
        "  results[\"Score\"] = results[\"Score\"].round(1)\n",
        "\n",
        "  return results\n",
        "\n",
        "def get_votes_df_from_vote_matrix(vote_matrix):\n",
        "  all_user_votes = []\n",
        "  for v in vote_matrix: \n",
        "    all_user_votes.append(pd.Series(vote_matrix[v][vote_matrix[v] > 0].sort_values().index.get_level_values(level=\"Title\"), name=v))\n",
        "  return pd.concat(all_user_votes, axis=1)\n",
        "\n",
        "def sheet_updater(gc, SHEETNAME, verbose=False, **options):\n",
        "\n",
        "  # Load sheets\n",
        "  votesheet = gc.open(SHEETNAME).worksheet('Votes')\n",
        "  #chartsheet = gc.open(SHEETNAME).worksheet('Chart')\n",
        "  metasheet = gc.open(SHEETNAME).worksheet('Titles')\n",
        "\n",
        "  # Get votes df\n",
        "  votes_df = get_votes_df(votesheet,**options)\n",
        "  if verbose: display(votes_df.head())\n",
        "\n",
        "  # Get vote matrix\n",
        "  vote_matrix = get_vote_matrix(votes_df)\n",
        "  if verbose: display(vote_matrix.head())\n",
        "  if verbose: print(\"Vote matrix shape:\", vote_matrix.shape)\n",
        "\n",
        "  # Append titles to vote matrix index\n",
        "  meta_df = get_meta_df(metasheet).sort_index()\n",
        "  #titles_df = get_titles_df(metasheet)\n",
        "  if verbose: display(meta_df.head())\n",
        "  if verbose: print(\"Meta df shape:\", meta_df.shape)\n",
        "\n",
        "  if len(meta_df) != len(vote_matrix):\n",
        "    print(len(meta_df),len(vote_matrix))\n",
        "    a=set(vote_matrix.index) - set(meta_df.index.get_level_values(level=\"ID\"))\n",
        "    b=set(meta_df.index.get_level_values(level=\"ID\")) - set(vote_matrix.index)\n",
        "    for title in a: print(title)\n",
        "    print(len(a),len(b))\n",
        "    print(\"\\n\\n\\n\")\n",
        "    for title in b: print(title[0])\n",
        "    raise Exception(\"Update meta_df\")\n",
        "\n",
        "  vote_matrix = get_vote_matrix_titled(vote_matrix, meta_df)\n",
        "  vote_matrix.to_csv(f\"/content/drive/MyDrive/{SHEETNAME}_vote_matrix.csv\")\n",
        "  print(\"Saved vote matrix:\", f\"/content/drive/MyDrive/{SHEETNAME}_vote_matrix.csv\")\n",
        "  if verbose: display(vote_matrix.head())\n",
        "\n",
        "  meta_df.to_csv(f\"/content/drive/MyDrive/{SHEETNAME}_meta_df.csv\")\n",
        "  print(\"Saved meta_df:\", f\"/content/drive/MyDrive/{SHEETNAME}_meta_df.csv\")\n",
        "\n",
        "  return meta_df, vote_matrix\n",
        "\n",
        "\n",
        "def load_data(load_from_sheet, vote_matrix_string=\"\", **options):\n",
        "\n",
        "  if load_from_sheet:\n",
        "\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "    from google.auth import default\n",
        "    creds, _ = default()\n",
        "\n",
        "    gc = gspread.authorize(creds)\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    meta_df, vote_matrix = sheet_updater(gc, **options)\n",
        "\n",
        "  elif vote_matrix_string != \"\":\n",
        "    import io\n",
        "    data = io.StringIO(vote_matrix_string)\n",
        "    vote_matrix = pd.read_csv(data, sep=\",\", index_col=[0,1])\n",
        "\n",
        "  else:\n",
        "    vote_matrix = pd.read_csv(options[\"vote_matrix_csv\"],index_col=[0,1])\n",
        "    meta_df = pd.read_csv(options[\"titles_csv\"], index_col=[0,1])\n",
        "\n",
        "  if options[\"remove_original_title\"]:\n",
        "\n",
        "    meta_df.sort_index(level=\"ID\",inplace=True)\n",
        "    vote_matrix.sort_index(level=\"ID\",inplace=True)\n",
        "\n",
        "    cleaned_title = vote_matrix.index.get_level_values(level=\"Title\")\n",
        "    cleaned_title = cleaned_title.where(cleaned_title.str[-1:] != ']', cleaned_title.str[:-1].str.split('[').str[1])\n",
        "    vote_matrix.index.get_level_values(level=\"Title\")\n",
        "    vote_matrix['Title'] = cleaned_title\n",
        "    vote_matrix.index = vote_matrix.index.droplevel(level=\"Title\")\n",
        "    vote_matrix.set_index('Title', append=True, inplace=True)\n",
        "\n",
        "    meta_df.index = vote_matrix.index\n",
        "\n",
        "  nantitles = vote_matrix.index.get_level_values(level=\"Title\").to_numpy() != vote_matrix.index.get_level_values(level=\"Title\").to_numpy()\n",
        "  vote_matrix.index = pd.MultiIndex.from_tuples([(x[0], x[0] if nan else x[1]) for x, nan in zip(vote_matrix.index, nantitles)], names=[\"ID\",\"Title\"])\n",
        "\n",
        "  vote_matrix_all_ranked = vote_matrix.mask(vote_matrix < 0, 25.5)  # to do: partial rankings here\n",
        "  all_user_votes = get_votes_df_from_vote_matrix(vote_matrix_all_ranked)\n",
        "\n",
        "  partial_rankings = get_partial_rankings(vote_matrix, size_dependent=options[\"size_dependent_borda\"])\n",
        "  #if options[\"DEFAULT_RANK_OPTION\"] =='BORDA_RANK_SIZE_DEPENDENT':\n",
        "  #  DEFAULT_RANK = get_results_df(vote_matrix, 1, 0, linear_pop_multiplier, list_sizes).sort_values(by=\"Rank\")\n",
        "  if options[\"DEFAULT_RANK_OPTION\"] =='BORDA_RANK':\n",
        "    DEFAULT_RANK = get_results_df(vote_matrix, 1, 0, linear_pop_multiplier, partial_rankings, size_dependent=options[\"size_dependent_borda\"]).sort_values(by=\"Rank\")\n",
        "  else:\n",
        "    DEFAULT_RANK = get_results_df(vote_matrix, 1, 0, \"vote_pop_multiplier\", partial_rankings, size_dependent=options[\"size_dependent_borda\"]).sort_values(by=\"Rank\")\n",
        "\n",
        "  meta_df = meta_df.loc[DEFAULT_RANK.index]\n",
        "\n",
        "  if query_tmdb:\n",
        "    query_tmdb_wrapper(DEFAULT_RANK, **options)\n",
        "\n",
        "  return vote_matrix, vote_matrix_all_ranked, all_user_votes, meta_df, DEFAULT_RANK\n",
        "\n",
        "\n",
        "##################################\n",
        "##################################\n",
        "##################################\n",
        "\n",
        "def query_tmdb_movie(df, metasheet, max_queries, api_key):\n",
        "\n",
        "  print(\"Searching TMDB...\")\n",
        "  low_lim, up_lim = 1980, 1989\n",
        "  print(\"DECADE LIMITS HARD CODED:\", low_lim, up_lim)\n",
        "\n",
        "  for i, id in enumerate(df.index):\n",
        "\n",
        "    if i > max_queries: break\n",
        "    title = id[1]\n",
        "\n",
        "    if df.loc[id][\"TMDB_id\"] == \"\":\n",
        "      print(\"Fetching ID for:\", title, i)\n",
        "      r = requests.get('https://api.themoviedb.org/3/search/movie?api_key='+api_key+'&query='+title)\n",
        "      parsed = json.loads(r.text)  \n",
        "\n",
        "      try:\n",
        "        for j, res in enumerate(parsed['results']):\n",
        "          if low_lim <= int(res['release_date'][:4]) <= up_lim:\n",
        "            df.loc[id, \"TMDB_id\"] = int(res['id'])\n",
        "            break\n",
        "\n",
        "      except (ValueError, KeyError):\n",
        "        print(json.dumps(parsed, indent=4, sort_keys=True))\n",
        "        set_with_dataframe(metasheet, df, include_index=True)\n",
        "\n",
        "    if len(set([df.loc[id, \"Release\"],df.loc[id,\"IMGID\"]]).intersection(set([\"\"]))) > 0:\n",
        "\n",
        "      print(\"Fetching metadata for\", title)\n",
        "      r = requests.get('https://api.themoviedb.org/3/movie/'+str(df.loc[id, \"TMDB_id\"])+'?api_key='+api_key)\n",
        "      r_credits = requests.get('https://api.themoviedb.org/3/movie/'+str(df.loc[id, \"TMDB_id\"])+'/credits?api_key='+api_key)\n",
        "      parsed = json.loads(r.text)\n",
        "      parsed_credits = json.loads(r_credits.text)\n",
        "\n",
        "      try:\n",
        "        parsed_crew = parsed_credits['crew']\n",
        "        parsed_cast = parsed_credits['cast']\n",
        "\n",
        "        df.loc[id, \"IMGID\"] = parsed['poster_path']\n",
        "        df.loc[id, \"Release\"] = parsed['release_date']\n",
        "        df.loc[id, \"Runtime\"] = parsed['runtime']\n",
        "        df.loc[id, \"Language\"] = parsed['original_language']\n",
        "        df.loc[id, \"Genres\"] = ','.join([g['name'] for g in parsed['genres']])\n",
        "\n",
        "        df.loc[id, \"Cast\"] = \",\".join([d[\"name\"] for d in parsed_cast if d[\"order\"] < 5])\n",
        "        df.loc[id, \"Director\"] = \",\".join([d[\"name\"] for d in parsed_crew if d[\"job\"] == \"Director\"])\n",
        "        df.loc[id, \"Producer\"] = \",\".join([d[\"name\"] for d in parsed_crew if d[\"job\"] == \"Producer\"])\n",
        "        df.loc[id, \"Writer\"] = \",\".join([d[\"name\"] for d in parsed_crew if d[\"job\"] == \"Writer\"])\n",
        "        df.loc[id, \"Sound Designer\"] = \",\".join([d[\"name\"] for d in parsed_crew if d[\"job\"] == \"Sound Designer\"])\n",
        "        df.loc[id, \"Editor\"] = \",\".join([d[\"name\"] for d in parsed_crew if d[\"job\"] == \"Editor\"])\n",
        "        df.loc[id, \"Director of Photography\"] = \",\".join([d[\"name\"] for d in parsed_crew if d[\"job\"] == \"Director of Photography\"])\n",
        "        df.loc[id, \"Composer\"] = \",\".join([d[\"name\"] for d in parsed_crew if d[\"job\"] == \"Original Music Composer\"])\n",
        "        df.loc[id, \"Art Direction\"] = \",\".join([d[\"name\"] for d in parsed_crew if d[\"job\"] == \"Art Direction\"])\n",
        "        df.loc[id, \"Production Design\"] = \",\".join([d[\"name\"] for d in parsed_crew if d[\"job\"] == \"Production Design\"])\n",
        "        df.loc[id, \"Costume Design\"] = \",\".join([d[\"name\"] for d in parsed_crew if d[\"job\"] == \"Costume Design\"])\n",
        "        df.loc[id, \"Makeup Artist\"] = \",\".join([d[\"name\"] for d in parsed_crew if d[\"job\"] == \"Makeup Artist\"])\n",
        "\n",
        "      except KeyError:\n",
        "        print(json.dumps(parsed, indent=4, sort_keys=True))\n",
        "        set_with_dataframe(metasheet, df, include_index=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "def query_tmdb_wrapper(DEFAULT_RANK, SHEETNAME, **options):\n",
        "\n",
        "  # from google.colab import auth\n",
        "  # auth.authenticate_user()\n",
        "\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  from google.auth import default\n",
        "  creds, _ = default()\n",
        "\n",
        "  gc = gspread.authorize(creds)\n",
        "\n",
        "  metasheet = gc.open(SHEETNAME).worksheet('Titles')\n",
        "\n",
        "  with open(\"/content/drive/MyDrive/tmdb_api_key.txt\", \"r\") as f:\n",
        "    api_key = f.read()[:-1]\n",
        "\n",
        "  meta_df_prior = get_meta_df(metasheet).sort_index()\n",
        "  meta_df_prior[\"Title\"] = DEFAULT_RANK.sort_index().index.get_level_values(level=\"Title\")\n",
        "  meta_df_prior.index = meta_df_prior.index.droplevel(level=\"Title\")\n",
        "  meta_df_prior.set_index('Title', append=True, inplace=True)\n",
        "\n",
        "  ids_to_query = DEFAULT_RANK.sort_values(by=\"Rank\").index.get_level_values(level=\"ID\")\n",
        "  meta_df_prior = meta_df_prior.loc[ids_to_query]\n",
        "  meta_df = query_tmdb_movie(meta_df_prior, metasheet, max_queries, api_key)\n",
        "\n",
        "  set_with_dataframe(metasheet, meta_df, include_index=True)\n",
        "\n",
        "def get_image_row(cc, preamble, meta_df, DEFAULT_RANK, link, database_id):\n",
        "\n",
        "  statprint = f\"\"\"\n",
        "  Voters: {len(cc.vote_matrix.columns)} <br>\n",
        "  Titles: {len(cc.vote_matrix)} <br>\n",
        "  Votes: {np.sum(np.sum(cc.vote_matrix.astype(bool)))} <br>\n",
        "  \"\"\"\n",
        "  \n",
        "  image_row = '<div id=\"carousel\">'\n",
        "  image_row += f\"<div class='slide'><div class='center'><h2 style='text-align:center'>{preamble}<h3 style='text-align:center'>{statprint}</div></div>\"\n",
        "  for index in meta_df.index:\n",
        "    image_row += '<div class=\"slide\">'\n",
        "    try:\n",
        "      image_row += f\"<h1 style='text-align:center'>{DEFAULT_RANK['Rank'].loc[index]}</h1><p style='text-align:center'>Score: {DEFAULT_RANK['Score'].loc[index]:.0f} | Votes: {DEFAULT_RANK['Votes'].loc[index]}<br></p>\"\n",
        "      image_row += '<a href='+link+str(int(meta_df.loc[index,database_id]))+' target = blank_>'\n",
        "      image_row += '<img src=\"https://image.tmdb.org/t/p/w600_and_h900_bestv2'\n",
        "      image_row += str(meta_df.loc[index,'IMGID']) + '\" alt = \"' + str(index[1]) + '\" style=\"width:200px\"></a>'\n",
        "    except ValueError:\n",
        "      print(\"image row value error:\", index)\n",
        "      pass\n",
        "    image_row += \"</div>\"\n",
        "  image_row += '</div>'\n",
        "  return image_row\n",
        "  \n",
        "def display_image_carousel(cc, TOP_ITEMS, preamble=\"\"):\n",
        "\n",
        "  image_row = get_image_row(cc, preamble, cc.meta_df[:TOP_ITEMS], cc.DEFAULT_RANK[:TOP_ITEMS], cc.options[\"link\"], cc.options[\"database_id\"])\n",
        "\n",
        "  display(HTML(\"\"\"\n",
        "\n",
        "  <style>\n",
        "\n",
        "  #carousel {\n",
        "      background-color: #ffffff00;    \n",
        "      overflow: visible;\n",
        "      white-space:nowrap;\n",
        "  }\n",
        "\n",
        "  #carousel .slide {\n",
        "      display: inline-block;\n",
        "      padding: 5px;\n",
        "  }\n",
        "\n",
        "  #carousel .center {\n",
        "    margin: 0;\n",
        "    position: relative;\n",
        "    top: 50%;\n",
        "    left: 5%;\n",
        "    transform: translate(-10%,-100%);\n",
        "  }\n",
        "    \n",
        "  </style>\"\"\"+image_row))\n",
        "\n",
        "class CompiledCharts:\n",
        "\n",
        "  def __init__(self, load_from_sheet, **options):\n",
        "\n",
        "    vote_matrix, vote_matrix_all_ranked, all_user_votes, meta_df, DEFAULT_RANK = load_data(load_from_sheet, **options)\n",
        "\n",
        "    self.vote_matrix = vote_matrix\n",
        "    self.vote_matrix_all_ranked = vote_matrix_all_ranked # unranked votes replaced with median vote\n",
        "    self.all_user_votes = all_user_votes # df of ranked vote lists\n",
        "    self.meta_df = meta_df\n",
        "    self.DEFAULT_RANK = DEFAULT_RANK\n",
        "    self.options = options\n",
        "\n",
        "    self.MAX_LENGTH = int(np.max(self.vote_matrix.values)) # Maximum list length\n",
        "    self.COUNTS = self.vote_matrix.astype(bool).sum(axis=1)\n",
        "    self.MOST_VOTES_TITLE = self.COUNTS.sort_values().index[-1][1]\n",
        "    self.MOST_VOTES = max(self.COUNTS) # Number of votes of most voted entry\n",
        "\n",
        "    self.vmc_ranked = self.vote_matrix_all_ranked.mask(self.vote_matrix_all_ranked>0, self.MAX_LENGTH+1-self.vote_matrix_all_ranked).corr()\n",
        "    self.vmc_unranked = self.vote_matrix_all_ranked.mask(self.vote_matrix_all_ranked>0, 1).corr()\n",
        "    self.voters = list(self.vote_matrix_all_ranked.columns)\n",
        "    self.list_sizes = get_list_sizes_from_vote_matrix(self.vote_matrix)\n",
        "    self.partial_rankings = get_partial_rankings(self.vote_matrix,options[\"size_dependent_borda\"])\n",
        "\n",
        "  def set_clusters(self, cluster_df, cluster_list):\n",
        "    self.cluster_df = cluster_df, \n",
        "    self.cluster_list = cluster_list\n",
        "\n",
        "  def set_links(self):\n",
        "    self.links_ranked = self.vmc_ranked.stack().reset_index()\n",
        "    self.links_unranked = self.vmc_ranked.stack().reset_index()\n",
        "    self.links_ranked.columns = self.links_unranked.columns = ['var1', 'var2', 'value']\n",
        "\n",
        "  def add_chart_voter(self):\n",
        "    \"\"\"Used to add chart voter. Generic new voter cannot have new titles\"\"\"\n",
        "    chart_voter = self.DEFAULT_RANK[:self.MAX_LENGTH].index.get_level_values(level=\"ID\").to_list()\n",
        "    chart_voter = pd.Series(chart_voter,index=(range(1,len(chart_voter)+1)))\n",
        "    self.vote_matrix_expanded, self.vote_matrix = add_voter_to_vote_matrix(self.vote_matrix_all_ranked, chart_voter, name=f\"Top {self.MAX_LENGTH} Classic\")\n",
        "    self.all_user_votes_expanded, self.all_user_votes = add_voter_to_all_user_votes(self.vote_matrix_all_ranked, self.all_user_votes, chart_voter, name=f\"Top {self.MAX_LENGTH} Classic\")\n",
        "    self.vmc_ranked_expanded = self.vote_matrix_expanded.mask(self.vote_matrix_expanded>0, self.MAX_LENGTH+1-self.vote_matrix_expanded).corr()\n",
        "    self.vmc_unranked_expanded = self.vote_matrix_expanded.mask(self.vote_matrix_expanded>0, 1).corr()\n",
        "    self.voters_expanded = list(self.vote_matrix_expanded.columns)\n",
        "\n",
        "def get_list_sizes_from_vote_matrix(vote_matrix):\n",
        "  \"\"\"\n",
        "  Needed for size-dependent Borda count\n",
        "  Cannot use all_user_votes because it doesn't contain info on which lists are unranked\n",
        "  \"\"\"\n",
        "  return vote_matrix.astype(bool).sum(axis=0)\n",
        "\n",
        "def get_partial_rankings(vote_matrix, size_dependent=False):\n",
        "  \"\"\"\n",
        "  Counts ballot sizes, number of ranked and unranked items, \n",
        "  avg rank of unranked items (=25.5 for completely unranked list of size 50)\n",
        "  \"\"\"\n",
        "  if size_dependent:\n",
        "    size = vote_matrix.astype(bool).sum(axis=0)\n",
        "  else: \n",
        "    size = pd.Series([max(vote_matrix.max(axis=1)) for _ in range(len(vote_matrix.columns))], index=vote_matrix.columns)\n",
        "\n",
        "  unranked = np.abs(vote_matrix.mask(vote_matrix>0,0).sum(axis=0))\n",
        "  ranked = size - unranked\n",
        "  avg_rank = 1+ranked+(unranked-1)/2\n",
        "  df = pd.DataFrame([size.values,ranked.values,unranked.values,avg_rank.values],index=[\"Size\",\"Ranked\",\"Unranked\",\"Avg_Unranked_Rank\"],columns=size.index)\n",
        "  df.loc[\"Avg_Unranked_Rank\"] = df.loc[\"Avg_Unranked_Rank\"].mask(df.loc[\"Unranked\"]==0,0)\n",
        "  #print(\"rounding unranked ballots\")\n",
        "  df.loc[\"Avg_Unranked_Rank\"] = df.loc[\"Avg_Unranked_Rank\"].round(0).astype(int) # rounding rank up to 26 => rounding points down to 25\n",
        "  return df\n",
        "\n",
        "def add_voter_to_vote_matrix(vote_matrix, vote_list, name=\"\"):\n",
        "  \"\"\"Used to add chart voter. Generic new voter cannot have new titles\"\"\"\n",
        "  vote_matrix_expanded = vote_matrix\n",
        "  vote_matrix_expanded[name] = np.zeros(len(vote_matrix_expanded))\n",
        "  vote_matrix_expanded.loc[vote_list.values, name] = vote_list.index.to_list()\n",
        "  return vote_matrix_expanded, vote_matrix_expanded.drop(name,axis=1)\n",
        "\n",
        "def add_voter_to_all_user_votes(vote_matrix, all_user_votes, vote_list, name=\"\"):\n",
        "\n",
        "  titles = vote_list.values\n",
        "  titles = vote_matrix.loc[titles].index.get_level_values(level=\"Title\")\n",
        "  all_user_votes[name] = titles\n",
        "  return all_user_votes, all_user_votes.drop(name,axis=1)\n",
        "\n",
        "def hover(hover_color='silver'):\n",
        "    return dict(selector=\"tr:hover\", props=[(\"background-color\", \"%s\" % hover_color)])\n",
        "\n",
        "def alternate_row_colors(background_color='gainsboro'):\n",
        "  return dict(selector='tr:nth-child(even)',props=[(\"background-color\", \"%s\" % background_color)])\n",
        "\n",
        "def color_signs(s):\n",
        "  '''\n",
        "  Color positive values green, negative values red, zero blue\n",
        "  '''\n",
        "  zeros=np.where(s==0)\n",
        "  s=np.where(s>0, \"color: green\", \"color: red\")\n",
        "  s[zeros]=\"color: blue\"\n",
        "  return s\n",
        "\n",
        "def print_df(a,Display,cc,round_score=False):\n",
        "\n",
        "  for i in a.index:\n",
        "    diff = a.loc[i,'Diff.']\n",
        "    if diff > 0: color = \"green\"\n",
        "    elif diff == 0: color = \"blue\"\n",
        "    else: color = \"red\"\n",
        "    title = i[0] if cc.options[\"print\"] == \"ID\" else i[1]\n",
        "    string = f\"[b]{a.loc[i,'Rank']:.0f}.[/b]\"\n",
        "    if round_score: string += f\" {title} | Score: {a.loc[i,'Score']:.0f} | Votes: {a.loc[i,'Votes']:.0f}\"\n",
        "    else: string += f\" {title} | Score: {a.loc[i,'Score']:.1f} | Votes: {a.loc[i,'Votes']:.0f}\"\n",
        "    if Display == \"RYM Print Diff.\": string += f\" | [color {color}]{diff:+.0f}[/color]\"\n",
        "    print(string)\n",
        "\n",
        "def print_metadf(a,item_type,Stats):\n",
        "  for i in a.index:\n",
        "    string = f\"[b]{a.loc[i,'Rank']:.0f}.[/b]\"\n",
        "    string += f\" {i} | Score: {a.loc[i,'Score']:.1f} | Votes: {a.loc[i,'Votes']:.0f} | {item_type}: {a.loc[i,'Titles']:.0f}\"\n",
        "    print(string)\n",
        "\n",
        "def get_norm_factor_dict(cc_dict):\n",
        "  \"\"\"Normalization factors for combined charts\"\"\"\n",
        "  max_votes = np.array([len(cc_dict[cc].vote_matrix.columns) for cc in cc_dict])\n",
        "  norm_factors = max(max_votes)/max_votes\n",
        "  return {cc: norm_factors[i] for i, cc in enumerate(cc_dict)}\n",
        "\n",
        "def main(options_list):\n",
        "\n",
        "  # Load all datasets into CompiledCharts instances\n",
        "  cc_dict = {options[\"dataname\"]: CompiledCharts(**options) for options in options_list}\n",
        "\n",
        "  # Display image carousels\n",
        "  for cc in cc_dict:\n",
        "    if cc == \"Film (Combined)\": continue\n",
        "    display_image_carousel(cc_dict[cc], TOP_ITEMS=100, preamble=cc_dict[cc].options[\"dataname\"])\n",
        "\n",
        "  return cc_dict\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  cc_dict = main(options_list)\n",
        "\n",
        "  # Normalize combined chart\n",
        "  film_charts = [\"Film (1980s)\", \"Film (1990s)\",\"Film (2000s)\",\"Film (2010s)\"]\n",
        "  cc = cc_dict[\"Film (Combined)\"]\n",
        "  cc_dict_film = {key:cc_dict[key] for key in cc_dict if key in film_charts}\n",
        "  norm_factors = get_norm_factor_dict(cc_dict_film)\n",
        "  vote_matrix = cc.vote_matrix\n",
        "  Weight, PopWeight = 1, 0\n",
        "  cc.DEFAULT_RANK = get_results_df(vote_matrix,Weight,PopWeight,\"vote_pop_multiplier\",cc.partial_rankings,cc.options[\"size_dependent_borda\"],norm_factors=norm_factors,cc_dict=cc_dict_film)\n",
        "  cc.MOST_VOTES = int(max(cc.DEFAULT_RANK[\"Votes\"]))\n",
        "  cc.MOST_VOTES_TITLE = cc.DEFAULT_RANK.sort_values(by=\"Votes\",ascending=False).iloc[0].name[1]\n",
        "\n",
        "\n",
        "\n",
        "#When adding new decade to combined film chart\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# def corrections(vote_matrix, name):\n",
        "#   \"\"\"Remove films that appear in multiple decades\"\"\"\n",
        "#   if name == \"Film (2010s)\":\n",
        "#     dupes = [\"[Film46927]\"]\n",
        "#   elif name == \"Film (2000s)\":\n",
        "#     dupes = [\"[Film14806]\", \"[Film2174]\",\"[Film888]\"]\n",
        "#   elif name == \"Film (1990s)\":\n",
        "#     dupes = [\"[Film145]\", \"[Film58385]\", \"[Film2530]\", \"[Film107328]\"]\n",
        "#   elif name == \"Film (1980s)\":\n",
        "#     dupes = [\"[Film10065]\"]\n",
        "#   else: return vote_matrix\n",
        "#   return vote_matrix.drop(dupes, axis=0)\n",
        "\n",
        "# def detect_duplicates_in_combined(df, cc_dict):\n",
        "#   dupes=df.index.duplicated(keep ='first')\n",
        "#   if sum(dupes)>1:\n",
        "#     dup_ids = df.loc[dupes].index\n",
        "#     display(dup_ids)\n",
        "#     for id in dup_ids:\n",
        "#       for cc in cc_dict:\n",
        "#         print(cc)\n",
        "#         try: \n",
        "#           x = cc_dict[cc].vote_matrix.loc[id]\n",
        "#           display(x[x>0])\n",
        "#         except KeyError: pass\n",
        "#       print(\"\\n\")\n",
        "#     raise Exception(\"Duplicates indices found\")\n",
        "\n",
        "# def merge_vote_matrices(cc_dict):\n",
        "#   all_vote_matrices = [corrections(cc_dict[cc].vote_matrix, cc) for cc in cc_dict]\n",
        "#   merged_vote_matrices = pd.concat(all_vote_matrices).fillna(0)\n",
        "#   detect_duplicates_in_combined(merged_vote_matrices, cc_dict)\n",
        "#   merged_vote_matrices.to_csv(f\"/content/drive/MyDrive/combined_film_vote_matrix.csv\")\n",
        "#   print(\"Saved vote matrix:\", f\"/content/drive/MyDrive/combined_film_vote_matrix.csv\")\n",
        "\n",
        "# def merge_meta_dfs(cc_dict):\n",
        "#   all_meta_dfs = [corrections(cc_dict[cc].meta_df, cc) for cc in cc_dict]\n",
        "#   merged_meta_dfs = pd.concat(all_meta_dfs)\n",
        "#   detect_duplicates_in_combined(merged_meta_dfs, cc_dict)\n",
        "#   merged_meta_dfs.to_csv(f\"/content/drive/MyDrive/combined_film_metadata.csv\")\n",
        "#   print(\"Saved metadata:\", f\"/content/drive/MyDrive/combined_film_metadata.csv\")\n",
        "\n",
        "# film_charts = [\"Film (1980s)\", \"Film (1990s)\",\"Film (2000s)\",\"Film (2010s)\"]\n",
        "# cc_dict_film = {key:cc_dict[key] for key in cc_dict if key in film_charts}\n",
        "\n",
        "# merge_vote_matrices(cc_dict_film)\n",
        "# merge_meta_dfs(cc_dict_film)\n",
        "\n",
        "\n",
        "\n",
        "####### old\n",
        "\n",
        "# from itertools import chain\n",
        "\n",
        "# def merge_default_Ranks(cc_dict):\n",
        "\n",
        "#   # decades = [[decade[-4:-1] for _ in range(len(cc_dict[decade].vote_matrix))] for decade in cc_dict]\n",
        "#   # decades = list(chain.from_iterable(decades))\n",
        "#   #merged[\"Decade\"] = decades\n",
        "\n",
        "#   film_charts = [\"Film (1990s)\",\"Film (2000s)\",\"Film (2010s)\"]\n",
        "\n",
        "#   all_default_ranks = [cc_dict[cc].DEFAULT_RANK for cc in cc_dict]\n",
        "#   max_votes = np.array([len(cc_dict[cc].vote_matrix.columns) for cc in cc_dict])\n",
        "#   norm_factors = max(max_votes)/max_votes\n",
        "#   norm_factors_expanded = [[norm_factors[i] for _ in range(len(cc_dict[chart].vote_matrix))] for i, chart in enumerate(cc_dict)]\n",
        "#   norm_factors_expanded = list(chain.from_iterable(norm_factors_expanded))\n",
        "\n",
        "#   merged = pd.concat(all_default_ranks)\n",
        "#   merged[\"Norm.Votes\"] = (merged[\"Votes\"]*norm_factors_expanded).astype(int)\n",
        "#   merged[\"Norm.Score\"] = (merged[\"Score\"]*norm_factors_expanded).astype(int)\n",
        "#   merged[\"Comb.Rank\"] = merged[\"Norm.Score\"].rank(ascending=False,method='min').astype(int)\n",
        "#   merged = merged.sort_values(by=\"Comb.Rank\",ascending=True)\n",
        "#   merged = merged[[\"Norm.Votes\",\"Norm.Score\",\"Comb.Rank\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgSvwwahFy0G"
      },
      "source": [
        "# Interactive Chart\n",
        "\n",
        "__Score Calculation:__ With default settings, the raw score is calculated according to a Borda count. That is, for a poll with a maximum ballot size of N, the top item gets N points, the second item gets N-1 points, etc. The points are summed over all ballots to determine the total raw score. Ties are broken by the number of votes.\n",
        "\n",
        "---\n",
        "\n",
        "The chart can be customized using two weights:\n",
        "\n",
        "__Top Weight:__ Determines the distribution of points for each item in a ranked ballot of votes. Negative weights give greater emphasis to the items ranked at the top of the ballot. The top ranked item always gets N points. (See plots below)\n",
        "\n",
        "__Pop Weight:__ Determines the popularity multiplier by which the raw score is multiplied to get the final score. Negative popularity weights emphasize items with few votes, positive weights emphasize items with many votes.\n",
        "\n",
        "---\n",
        "\n",
        "Some example charts:\n",
        "\n",
        "__Borda Count__: Top Weight = Pop Weight = 0.\n",
        "\n",
        "__Esoteric Chart__: Top weight = -5, Pop Weight = -15. Highlights items with few voters but high placements.\n",
        "\n",
        "__Unique Items__: Top Weight = 0, Pop Weight = -20. Ranking of items that have received only one vote. (Not true for combined chart)\n",
        "\n",
        "__Gold Medals__: Top Weight = -10, Pop Weight = 0. Only the top-ranked items get any points. Dividing the score by N yields the number of \"gold medals\" received by the respective item. (Not true for combined film chart)\n",
        "\n",
        "__Classic Chart__: Top Weight = 0, Classic = True. Setting this checkbox to true will multiply the raw score by the number of votes, disabling custom popularity weighting. The Top Weight can still be adjusted.\n",
        "\n",
        "__Metadata Charts__: Use the \"Rank\" drop-down menu to create metadata charts. I recommend using Classic = False and going with a simple Borda count. Play around with the weights if the results from the Borda count are too skewed because of a dominant top film (e.g. Mulholland Drive)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQZyXME13VxJ",
        "cellView": "form"
      },
      "source": [
        "#@markdown <- Run this cell to activate the widgets. Re-run if the widgets disappear. If anything else breaks, try re-running all the cells from the top, else contact me on RYM (YasashiiDia).\n",
        "\n",
        "def autolabel(ax, labels):\n",
        "  \"\"\"Put labels inside rectangles of bar plot\"\"\"\n",
        "  rects = ax.patches\n",
        "  n = len(rects)\n",
        "  for i, (label, rect) in enumerate(zip(labels,rects)):\n",
        "    height = 2\n",
        "    ax.text((i+0.55)/n,0.1,label,transform=ax.transAxes,\n",
        "            ha='center', va='bottom', rotation=90, color='black')\n",
        "\n",
        "def style_df(a, metacols):\n",
        "\n",
        "  a_styled = a.style.set_properties(**{'text-align': 'center'})#.hide_index(\"ID\") outdated pandas\n",
        "  a_styled = a_styled.set_table_styles([dict(selector='th', props=[('text-align', 'center')])]) # centering index name\n",
        "  a_styled = a_styled.format(\"{:.1f}\",subset=['Score'])\n",
        "  a_styled = a_styled.format(\"{:+.0f}\",subset=['Diff.'])\n",
        "  a_styled = a_styled.format(\"{:.0f}\",subset=['Rank','Votes'])\n",
        "  if \"Runtime\" in metacols: a_styled = a_styled.format(\"{:.0f}\",subset=['Runtime'])\n",
        "  if \"Episodes\" in metacols: a_styled = a_styled.format(\"{:.0f}\",subset=['Episodes'])\n",
        "  a_styled.apply(color_signs, axis=0, subset=['Diff.'])\n",
        "  return a_styled\n",
        "\n",
        "def style_metadf(a):\n",
        "\n",
        "  a_styled = a.style.set_properties(**{'text-align': 'center'})#.hide_index(\"ID\") outdated pandas\n",
        "  a_styled = a_styled.set_table_styles([dict(selector='th', props=[('text-align', 'center')])]) # centering index name\n",
        "  a_styled = a_styled.format(\"{:.1f}\",subset=['Score'])\n",
        "  #a_styled = a_styled.format(\"{:+.0f}\",subset=['Diff.'])\n",
        "  a_styled = a_styled.format(\"{:.0f}\",subset=['Rank','Votes'])\n",
        "  #a_styled.apply(color_signs, axis=0, subset=['Diff.'])\n",
        "  return a_styled\n",
        "\n",
        "def filt(vote_matrix, cc, meta_df_display, Results, Weight, PopWeight, Classic, pop_multiplier,Stats):\n",
        "\n",
        "  norm_factors_passed = norm_factors if cc.options[\"dataname\"] == \"Film (Combined)\" else []\n",
        "  cc_dict_passed = cc_dict_film if cc.options[\"dataname\"] == \"Film (Combined)\" else []\n",
        "\n",
        "  if Classic:\n",
        "    results = get_results_df(vote_matrix,Weight,PopWeight,\"vote_pop_multiplier\",cc.partial_rankings,cc.options[\"size_dependent_borda\"],norm_factors=norm_factors_passed,cc_dict=cc_dict_passed)\n",
        "  else:\n",
        "    results = get_results_df(vote_matrix, Weight, PopWeight, pop_multiplier, cc.partial_rankings,cc.options[\"size_dependent_borda\"],norm_factors=norm_factors_passed,cc_dict=cc_dict_passed)\n",
        "    \n",
        "  results = pd.concat([results,meta_df_display],axis=1)\n",
        "\n",
        "  if Stats in [\"First Air Date\", \"Last Air Date\", \"Release\"]:\n",
        "    results[Stats] = results[Stats].str[:4]\n",
        "\n",
        "  type_plural = cc.options[\"type\"] + \"s\" if cc.options[\"type\"][-1] != \"s\" else cc.options[\"type\"]\n",
        "\n",
        "  if Stats not in [cc.options[\"type\"]]:\n",
        "    try:\n",
        "      results[Stats] = results[Stats].astype(str).str.split(\",\")\n",
        "      results = results.explode(Stats)\n",
        "\n",
        "      if Stats in [\"Cast\"]:\n",
        "        statcounts = results.index.value_counts(sort=False)\n",
        "        multipliers = [1-i/c for c in statcounts.values for i in range(c)]\n",
        "        results[\"Score\"] *= multipliers\n",
        "\n",
        "      statsgroup = results.groupby(Stats)\n",
        "      results = statsgroup[['Score','Votes']].sum()\n",
        "      results[type_plural] = [\", \".join([f[1] for f in g]) for g in statsgroup.groups.values()]\n",
        "      results[\"Titles\"] = statsgroup.size()\n",
        "      try: results.drop(\"nan\", axis=0, inplace=True)\n",
        "      except KeyError: pass\n",
        "      results[\"Score\"] += 0.0001*results[\"Votes\"] + 0.00001*results[\"Titles\"]\n",
        "      results[\"Rank\"] = results[\"Score\"].rank(ascending=False,method='min').astype(int)\n",
        "      results = results.sort_values(by=\"Rank\")\n",
        "      results = results[[\"Rank\",\"Score\",\"Votes\",\"Titles\",type_plural]]\n",
        "      return results[:Results]\n",
        "      \n",
        "    except KeyError: \n",
        "      #print(\"this means dataset has been changed but Stats still stuck on value that doesn't exist in new dataset\")\n",
        "      pass\n",
        "\n",
        "  results = results.sort_values(by=\"Rank\")\n",
        "  results[\"Diff.\"] = cc.DEFAULT_RANK[\"Rank\"] - results[\"Rank\"]\n",
        "  results = results[[\"Rank\",\"Score\",\"Votes\",\"Diff.\"]+cc.options[\"metacols\"]]\n",
        "\n",
        "  return results[:Results]\n",
        "\n",
        "def plot_weights(Weight,PopWeight,Classic,pop_multiplier,most_votes,most_votes_title,max_length):\n",
        "\n",
        "  fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
        "\n",
        "  # Point distribution\n",
        "  x = np.arange(1,51)\n",
        "  y = superellipse(x-1,n=Weight,a=1,b=1,size=max_length) # x-1 to move superellipse upwards\n",
        "  ax[0].scatter(x, y)\n",
        "  ax[0].plot([1,max_length],[max_length,1], label=\"Borda\", ls=\"--\",c=\"darkgrey\")\n",
        "  ax[0].set_xlabel(\"Ballot Position\")\n",
        "  ax[0].set_ylabel(\"Points\")\n",
        "  ax[0].set_ylim(0,1.1*max_length)\n",
        "\n",
        "  # Popularity multipliers\n",
        "  x = np.arange(1,most_votes+1)\n",
        "  y = x if Classic else pop_multiplier(x, most_votes, PopWeight)\n",
        "  ax[1].scatter(x,y)\n",
        "  ax[1].set_xlabel(\"Votes\")\n",
        "  ax[1].set_ylabel(\"Popularity Multiplier\")\n",
        "  if Classic: ax[1].set_ylim(0,1.1*most_votes) \n",
        "  else: ax[1].set_ylim(-0.1,2.1)\n",
        "  ax[1].axvline(most_votes,ls=\"--\",c=\"darkgrey\",label=f\"Most Votes ({most_votes}): {most_votes_title}\")\n",
        "  \n",
        "  for a in ax: a.legend(loc=\"best\")#\"upper center\")\n",
        "  fig.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "def display_df(Dataset,Results,Weight,PopWeight,Plot,Display,Classic,Stats):\n",
        "\n",
        "  classic_w.observe(observe_classic_w, 'value')\n",
        "  \n",
        "  cc = cc_dict[Dataset]\n",
        "  options = cc.options\n",
        "  metacols = options[\"metacols\"]\n",
        "\n",
        "  meta_df_display = pd.read_csv(options[\"titles_csv\"], index_col=[0,1],header=0,usecols=[\"ID\",\"Title\"]+metacols)[metacols]\n",
        "  try: meta_df_display[\"Release\"] = meta_df_display[\"Release\"].astype(str)\n",
        "  except KeyError: pass\n",
        "\n",
        "  Weight = WEIGHT_DISTRIBUTION[Weight+10]\n",
        "\n",
        "  PopWeight *= 10\n",
        "\n",
        "  if np.abs(PopWeight) <= 100:\n",
        "    pop_multiplier = linear_pop_multiplier\n",
        "  else:\n",
        "    PopWeight -= np.sign(PopWeight)*100\n",
        "    pop_multiplier = elliptical_pop_multiplier\n",
        "\n",
        "  vm = cc.vote_matrix\n",
        "  a = filt(vm, cc, meta_df_display, Results, Weight,PopWeight,Classic,pop_multiplier,Stats)\n",
        "\n",
        "  most_votes = cc.MOST_VOTES\n",
        "  most_votes_title = cc.MOST_VOTES_TITLE\n",
        "\n",
        "  if Plot:\n",
        "    plot_weights(Weight,PopWeight,Classic,pop_multiplier,most_votes,most_votes_title,cc.MAX_LENGTH)\n",
        "\n",
        "  if Display == \"DataFrame\":\n",
        "    if Stats == options[\"type\"]: a_styled = style_df(a, metacols)\n",
        "    else: a_styled = style_metadf(a)\n",
        "    display(a_styled)\n",
        "\n",
        "  elif Display in [\"RYM Print\", \"RYM Print Diff.\"]:\n",
        "    type_plural = cc.options[\"type\"] + \"s\" if cc.options[\"type\"][-1] != \"s\" else cc.options[\"type\"]\n",
        "    if Stats == options[\"type\"]: print_df(a,Display,cc)\n",
        "    else: print_metadf(a,type_plural,Stats)\n",
        "\n",
        "\n",
        "WEIGHT_DISTRIBUTION = list(np.linspace(0.1,0.9,10)) + list(np.linspace(1,5,11))\n",
        "startset = list(cc_dict.keys())[0]\n",
        "start_vm = cc_dict[startset].vote_matrix\n",
        "\n",
        "# Widgets\n",
        "layout={'width': '350px'}\n",
        "res_w = widgets.IntSlider(min=10, max=len(start_vm)+10, step=10,layout=layout,value=10,description='Results:',continuous_updates=False)\n",
        "disable_pop_weight=False\n",
        "pop_weight = widgets.IntSlider(min=-20, max=20, step=1,layout=layout,value=0,description='Pop Weight:',continuous_updates=False, disabled=disable_pop_weight)\n",
        "\n",
        "def observe_classic_w(*args):\n",
        "  \"\"\"Freeze pop weight when classic true\"\"\"\n",
        "  pop_weight.disabled = classic_w.value\n",
        "\n",
        "def observe_data_selection_w(*args):\n",
        "  \"\"\"Adjust available stats selection when chaing dataset\"\"\"\n",
        "  dataset = data_selection_w.value\n",
        "  stats_w.options = [cc_dict[dataset].options[\"type\"]] + cc_dict[dataset].options[\"metacols\"]\n",
        "\n",
        "top_weight = widgets.IntSlider(min=-10, max=10, step=1,layout=layout,value=0,description='Top Weight:',continuous_updates=False)\n",
        "plot_w = widgets.Checkbox(value=True,description='Plot Point Distribution')\n",
        "classic_w = widgets.Checkbox(value=False,description='Classic')\n",
        "display_w = widgets.Dropdown(options=['DataFrame','RYM Print','RYM Print Diff.'], value='DataFrame', description='Display:', disabled=False)\n",
        "#input_w = widgets.Dropdown(options=['Full'], value='Full', description='Input:', disabled=False)\n",
        "\n",
        "startset = list(cc_dict.keys())[0]\n",
        "data_selection_w = widgets.Dropdown(options=list(cc_dict.keys()), value=startset, description='Dataset:', disabled=False)\n",
        "stats_options = [cc_dict[startset].options[\"type\"]] + cc_dict[startset].options[\"metacols\"]\n",
        "stats_w = widgets.Dropdown(options=stats_options, description='Rank:', disabled=False)\n",
        "\n",
        "def on_data_change(change):\n",
        "    if change['type'] == 'change' and change['name'] == 'value':\n",
        "        observe_data_selection_w(data_selection_w, 'value')\n",
        "\n",
        "data_selection_w.observe(on_data_change)\n",
        "\n",
        "ws = [res_w,plot_w,data_selection_w,display_w,stats_w,classic_w,top_weight,pop_weight]\n",
        "\n",
        "out = widgets.interactive_output(display_df,{'Dataset':data_selection_w,'Results':res_w,'Weight':top_weight,'PopWeight':pop_weight,\"Plot\":plot_w,\"Display\":display_w,\"Classic\":classic_w,'Stats':stats_w})\n",
        "ui = widgets.GridBox(ws, layout=widgets.Layout(grid_template_columns=\"repeat(2, 400px)\"))\n",
        "\n",
        "display(ui, out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQUqXyqRlQoK"
      },
      "source": [
        "# Voter Correlations\n",
        "\n",
        "Select a voter to display how closely their list is correlated with the lists of all other voters. Also displayed in green are all the votes in common. The opacity is determined by the difference in ranking with the selected voter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdfUo2rJkM9I",
        "cellView": "form"
      },
      "source": [
        "#@markdown <- Run this cell to activate the widgets. Re-run if the widgets disappear. If anything else breaks, try re-running all the cells from the top, else contact me on RYM (YasashiiDia).\n",
        "\n",
        "import ipywidgets as widgets\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
        "\n",
        "def highlight_common(col, titles, props=''):\n",
        "\n",
        "    mask = np.isin(col.values, titles)\n",
        "    return np.where(mask, props, '')\n",
        "\n",
        "def highlight_common_diff(col, titles, MAX_LENGTH, props=''):\n",
        "    \"\"\"\n",
        "    Highlight elements in col that are also in titles\n",
        "    Alpha of highlight color increases with proximity of common elements along row axis\n",
        "    \"\"\"\n",
        "    mask = np.isin(col.values, titles)\n",
        "    titles_pos = [np.where(titles==c)[0][0] for c in col[mask]]\n",
        "    col_pos = np.arange(len(col))[mask]\n",
        "    diff = list(1-np.abs(col_pos-titles_pos)/MAX_LENGTH)\n",
        "    props = [\"\" if not m else props+f\"{diff.pop(0):.2f})\" for m in mask]  \n",
        "    return props\n",
        "\n",
        "def style_df2(a, MAX_LENGTH, Voter, Shade):\n",
        "    \n",
        "    a_styled = a.style.set_properties(**{'text-align': 'center'})\n",
        "    a_styled = a_styled.set_table_styles([dict(selector='th', props=[('text-align', 'center')])]) # centering index name\n",
        "    titles = a[Voter].values\n",
        "\n",
        "    if Shade:\n",
        "      a_styled.apply(highlight_common_diff, args=(titles,MAX_LENGTH), axis=0, props='color:black;background-color:rgba(60, 179, 113, ')#mediumseagreen')\n",
        "\n",
        "    return a_styled\n",
        "\n",
        "def filt2(vmc, all_user_votes, Voter):\n",
        "  \n",
        "  c = vmc[Voter].sort_values(ascending=False)\n",
        "\n",
        "  col_arrays = [all_user_votes[c.index].columns, c.values.round(2)]\n",
        "  multi_cols = pd.MultiIndex.from_arrays(col_arrays, names=[\"Voter\",\"Correlation\"])\n",
        "  votes = all_user_votes[c.index].values\n",
        "  results = pd.DataFrame(votes,index=range(1,len(all_user_votes)+1),columns=multi_cols,copy=True)\n",
        "  results.index.name = \"Rank\"\n",
        "  return results\n",
        "\n",
        "def display_df2(Dataset, Voter, Display, RankedCorr, Shade, IncludeCharts=False):\n",
        "\n",
        "  cc = cc_dict[Dataset]\n",
        "  options = cc.options\n",
        "\n",
        "  if IncludeCharts:\n",
        "    vmc = cc.vmc_ranked_expanded if RankedCorr else cc.vmc_unranked_expanded\n",
        "    all_user_votes = cc.all_user_votes_expanded\n",
        "  else:\n",
        "    vmc = cc.vmc_ranked if RankedCorr else cc.vmc_unranked\n",
        "    all_user_votes = cc.all_user_votes\n",
        "\n",
        "  try:\n",
        "    if Display == \"DataFrame\":\n",
        "      #if (not IncludeCharts) and Voter in chart_voters: Voter = voters[0]\n",
        "      a = filt2(vmc, all_user_votes, Voter)\n",
        "      #if not IncludeCharts: a.drop(chart_voters, axis=1, level=0, inplace=True)\n",
        "      a_styled = style_df2(a, cc.MAX_LENGTH, Voter, Shade)\n",
        "      display(a_styled)\n",
        "\n",
        "    elif Display == \"RYM Print\":\n",
        "      a=vmc[Voter].sort_values(ascending=False)\n",
        "      for v in a.index:\n",
        "        print(f\"{v}: {a.loc[v]:.2f}\")\n",
        "\n",
        "  except KeyError:\n",
        "    return\n",
        "\n",
        "def on_data_change2(change):\n",
        "  if change['type'] == 'change' and change['name'] == 'value':\n",
        "    dataset = data_selection_w2.value\n",
        "    voters = cc_dict[dataset].voters_expanded if include_charts_w.value else cc_dict[dataset].voters\n",
        "    voter_w.options = [voters[-1]] + voters[:-1] if include_charts_w.value else voters\n",
        "\n",
        "def on_top50_change(change):\n",
        "  if change['type'] == 'change' and change['name'] == 'value':\n",
        "    dataset = data_selection_w2.value\n",
        "    voters = cc_dict[dataset].voters_expanded if include_charts_w.value else cc_dict[dataset].voters\n",
        "    voter_w.options = [voters[-1]] + voters[:-1] if include_charts_w.value else voters\n",
        "\n",
        "for cc in cc_dict: \n",
        "  if cc == \"Film (Combined)\": continue\n",
        "  cc_dict[cc].add_chart_voter() \n",
        "\n",
        "# Widgets\n",
        "startset = list(cc_dict.keys())[0]\n",
        "startvoters = cc_dict[startset].voters\n",
        "sel = list(cc_dict.keys())\n",
        "sel.remove(\"Film (Combined)\")\n",
        "data_selection_w2 = widgets.Dropdown(options=sel, value=startset, description='Dataset:', disabled=False)\n",
        "data_selection_w2.observe(on_data_change2)\n",
        "\n",
        "voter_w = widgets.Dropdown(options=startvoters, value=startvoters[0], description='Voter:', disabled=False)\n",
        "display_w_n = widgets.Dropdown(options=['DataFrame','RYM Print'], value='DataFrame', description='Display:', disabled=False)\n",
        "ranked_correlations_w = widgets.Checkbox(value=True,description='Use rank info for correlations')\n",
        "shading_w = widgets.Checkbox(value=True,description='Highlight common votes')\n",
        "include_charts_w = widgets.Checkbox(value=False,description='Include Top 50')\n",
        "include_charts_w.observe(on_top50_change)\n",
        "\n",
        "ws_n = [data_selection_w2,display_w_n,voter_w,ranked_correlations_w,shading_w,include_charts_w]\n",
        "\n",
        "out_n = widgets.interactive_output(display_df2,{'Dataset':data_selection_w2,'Voter':voter_w,'Display':display_w_n,'RankedCorr':ranked_correlations_w,'Shade':shading_w,'IncludeCharts':include_charts_w})\n",
        "ui_n = widgets.GridBox(ws_n, layout=widgets.Layout(grid_template_columns=\"repeat(2, 400px)\"))\n",
        "\n",
        "display(ui_n, out_n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En-6CHRvTH24"
      },
      "source": [
        "# Voter Recommendations\n",
        "\n",
        "Select a voter and create a chart based on other voters whose correlations are within a specified range of the original voter. Filter items in the list of the original voter to get recommendations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "108AHSDITKaK",
        "cellView": "form"
      },
      "source": [
        "#@markdown <- Run this cell to activate the widgets. Re-run if the widgets disappear. If anything else breaks, try re-running all the cells from the top, else contact me on RYM (YasashiiDia).\n",
        "\n",
        "def style_df_rec(a, already_voted):\n",
        "    \n",
        "    a_styled = a.style.set_properties(**{'text-align': 'center'})\n",
        "    a_styled = a_styled.set_table_styles([dict(selector='th', props=[('text-align', 'center')])]) # centering index name\n",
        "    a_styled = a_styled.format(\"{:+.0f}\",subset=['Score','Diff.'])\n",
        "    a_styled.apply(color_signs, axis=0, subset=['Diff.'])\n",
        "\n",
        "    # Highligh already voted    \n",
        "    mask = pd.Series((np.isin(a.index.get_level_values(level=\"Title\"), already_voted)), index=a.index)\n",
        "    color = mask.map({True: 'background-color: darkgrey', False: ''})\n",
        "    a_styled.apply(lambda s: color)\n",
        "\n",
        "    return a_styled\n",
        "\n",
        "def filt3(vmc, Voter):\n",
        "\n",
        "  c = vmc[Voter].sort_values(ascending=False)\n",
        "  col_arrays = [all_user_votes[c.index].columns, c.values.round(2)]\n",
        "  multi_cols = pd.MultiIndex.from_arrays(col_arrays, names=[\"Voter\",\"Correlation\"])\n",
        "  votes = all_user_votes[c.index].values\n",
        "  results = pd.DataFrame(votes,index=range(1,len(all_user_votes)+1),columns=multi_cols,copy=True)\n",
        "  results.index.name = \"Rank\"\n",
        "  return results\n",
        "\n",
        "def display_df_rec(Dataset, Results, Voter, Display, RankedCorr, Thresh, Hide):\n",
        "\n",
        "  observe_data_selection_w3_voters(data_selection_w3, 'value')\n",
        "  cc = cc_dict[Dataset]\n",
        "  options = cc.options\n",
        "  vmc_stored.set_vmc(cc.vmc_ranked if RankedCorr else cc.vmc_unranked)\n",
        "  vmc = vmc_stored.vmc\n",
        "\n",
        "  voter_w_rec.observe(observe_voter, names=['value','max'])\n",
        "\n",
        "  try: already_voted = cc.all_user_votes[Voter].values\n",
        "  except KeyError: return\n",
        "\n",
        "  voters = vmc[Voter]\n",
        "  voters = voters.where(Thresh[0] <= voters)\n",
        "  voters = voters.where(Thresh[1] >= voters).dropna().index.to_list()\n",
        "  vm = cc.vote_matrix[voters]\n",
        "  vote_counts = vm.mask(vm>0,1).sum(axis=1)\n",
        "  vm = vm[vote_counts > 0]\n",
        "  results = get_results_df(vm,1,len(vmc),\"vote_pop_multiplier\",cc.partial_rankings,cc.options[\"size_dependent_borda\"])\n",
        "\n",
        "  if Hide: \n",
        "    try: results = results.drop(already_voted,level=\"Title\")\n",
        "    except KeyError: pass\n",
        "    results[\"Rank\"] = results[\"Score\"].rank(ascending=False,method='min').astype(int)\n",
        "\n",
        "  results[\"Diff.\"] = cc.DEFAULT_RANK[\"Rank\"] - results[\"Rank\"]\n",
        "  results = results.sort_values(by=\"Rank\")[:Results]\n",
        "\n",
        "  voterprint = [(v,round(c,2)) for v, c in zip(voters,vmc[Voter].loc[voters])]\n",
        "  voterprint = sorted(voterprint, key = lambda x: -x[1])\n",
        "\n",
        "  if Display == \"DataFrame\":\n",
        "    print(\"Recommendations from:\", voterprint)\n",
        "    results_styled = style_df_rec(results, already_voted)\n",
        "    display(results_styled)\n",
        "\n",
        "  elif Display in [\"RYM Print\", \"RYM Print Diff.\"]:\n",
        "    print(\"Recommendations from:\", voterprint, \"\\n\")\n",
        "    print_df(results,Display,cc,round_score=True)\n",
        "\n",
        "class VMC:\n",
        "  def __init__(self, vmc):\n",
        "    self.vmc = vmc\n",
        "  def set_vmc(self,vmc):\n",
        "    #print(\"setting new vmc\",np.random.rand(1))\n",
        "    self.vmc = vmc\n",
        "\n",
        "def observe_voter(*args):\n",
        "  \"\"\"Set corr max depending on voter\"\"\"\n",
        "  voter = voter_w_rec.value\n",
        "  voter_max_corr = sorted(vmc_stored.vmc[voter])[-2]\n",
        "  voter_max_corr = min(1.0, voter_max_corr + 0.01)\n",
        "  thresh_rec.max = voter_max_corr\n",
        "  #thresh_rec.value = [voter_max_corr/2, voter_max_corr] # will update df twice\n",
        "\n",
        "def observe_data_selection_w3_voters(*args):\n",
        "  \"\"\"Adjust available voters when changing dataset\"\"\"\n",
        "  dataset = data_selection_w3.value\n",
        "  voter_w_rec.options = cc_dict[dataset].voters\n",
        "\n",
        "startset = list(cc_dict.keys())[0]\n",
        "startvoters = cc_dict[startset].voters\n",
        "start_vmc = cc_dict[startset].vmc_ranked\n",
        "start_vmc_unranked = cc_dict[startset].vmc_unranked\n",
        "start_max_corr = sorted(start_vmc[startvoters[0]])[-2]\n",
        "start_value_corr = [start_max_corr/2,start_max_corr]\n",
        "start_min_corr = min(np.amin(start_vmc.to_numpy()),np.amin(start_vmc_unranked.to_numpy()))\n",
        "vmc_stored = VMC(start_vmc_unranked)\n",
        "\n",
        "sel = list(cc_dict.keys())\n",
        "sel.remove(\"Film (Combined)\")\n",
        "data_selection_w3 = widgets.Dropdown(options=sel, value=startset, description='Dataset:', disabled=False)\n",
        "voter_w_rec = widgets.Dropdown(options=startvoters, value=startvoters[0], description='Voter:', disabled=False)\n",
        "\n",
        "results_rec = widgets.IntSlider(min=10, max=len(cc_dict[startset].vote_matrix)+10, step=10, layout=layout, value=10,description='Results:',continuous_update=False)\n",
        "display_w_rec = widgets.Dropdown(options=['DataFrame','RYM Print','RYM Print Diff.'], value='DataFrame', description='Display:', disabled=False)\n",
        "ranked_correlations_rec = widgets.Checkbox(value=True,description='Use rank info for correlations')\n",
        "hide_voted_rec = widgets.Checkbox(value=True,description='Filter already voted')\n",
        "thresh_rec = widgets.FloatRangeSlider(min=start_min_corr, max=start_max_corr, step=0.01, layout=layout, value=[start_min_corr, start_max_corr],description='Correlation:',continuous_update=False)\n",
        "\n",
        "ws_rec = [data_selection_w3,display_w_rec,voter_w_rec,ranked_correlations_rec,thresh_rec,hide_voted_rec,results_rec]\n",
        "\n",
        "out_rec = widgets.interactive_output(display_df_rec,{'Dataset':data_selection_w3,'Results':results_rec,'Voter':voter_w_rec,'Display':display_w_rec,'RankedCorr':ranked_correlations_rec,'Thresh':thresh_rec,'Hide':hide_voted_rec})\n",
        "ui_rec = widgets.GridBox(ws_rec, layout=widgets.Layout(grid_template_columns=\"repeat(2, 400px)\"))\n",
        "\n",
        "display(ui_rec, out_rec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1dEBctw6R0n"
      },
      "source": [
        "# Voter Network\n",
        "\n",
        "Plot a network of voters, where voters are connected if they share a correlation above a chosen threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abCzsSfdirZo",
        "cellView": "form"
      },
      "source": [
        "#@markdown <- Run this cell to active the widgets. Re-run if the widgets disappear. If anything else breaks, try re-running all the cells from the top, else contact me on RYM (YasashiiDia).\n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "def display_df_net(Dataset, Plot, Width, Height, Thresh, SelfCorr):\n",
        "\n",
        "  observe_data_selection_w4_max_corr(data_selection_w4, 'value')\n",
        "  cc = cc_dict[Dataset]\n",
        "  links = cc.links_ranked\n",
        "\n",
        "  # Keep only correlation over a threshold and remove self correlation (cor(A,A)=1)\n",
        "  links_filtered=links.loc[links['value'] > Thresh]\n",
        "  if not SelfCorr:\n",
        "    links_filtered=links_filtered.loc[links_filtered['var1'] != links_filtered['var2']]\n",
        "\n",
        "  # Build graph\n",
        "  G=nx.from_pandas_edgelist(links_filtered, 'var1', 'var2')\n",
        "\n",
        "  plt.figure(1,figsize=(Width,Height))\n",
        "\n",
        "  if Plot == \"Default\":\n",
        "    nx.draw(G, with_labels=True, node_color='cornflowerblue', node_size=400, edge_color='grey', linewidths=0.01, font_size=15, font_color=\"black\")\n",
        "  elif Plot == \"Kamada-Kawai\":\n",
        "    nx.draw_kamada_kawai(G, with_labels=True, node_color='cornflowerblue', node_size=400, edge_color='grey', linewidths=0.01, font_size=15, font_color=\"black\")\n",
        "  elif Plot == \"Circular\":\n",
        "    nx.draw_circular(G, with_labels=True, node_color='cornflowerblue', node_size=400, edge_color='grey', linewidths=0.01, font_size=15, font_color=\"black\")\n",
        "\n",
        "\n",
        "startset = list(cc_dict.keys())[0]\n",
        "start_vmc = cc_dict[startset].vmc_ranked\n",
        "MAX_CORRELATION = round(start_vmc[start_vmc<1].max().max(), 2)\n",
        "for cc in cc_dict: cc_dict[cc].set_links()\n",
        "\n",
        "# Widgets\n",
        "layout={'width': '350px'}\n",
        "net_w = widgets.Dropdown(options=[\"Default\",\"Kamada-Kawai\",\"Circular\"], value=\"Default\", description='Network:', disabled=False)\n",
        "width_w = widgets.IntSlider(min=5, max=40, step=1, layout=layout, value=12,description='Width:')\n",
        "height_w = widgets.IntSlider(min=5, max=40, step=1, layout=layout, value=12,description='Height:')\n",
        "thresh_w = widgets.FloatSlider(min=0, max=MAX_CORRELATION, step=0.01, layout=layout, value=2*MAX_CORRELATION/3,description='Threshold:')\n",
        "self_corr_w = widgets.Checkbox(value=False,description='Self-Correlation')\n",
        "\n",
        "sel = list(cc_dict.keys())\n",
        "sel.remove(\"Film (Combined)\")\n",
        "data_selection_w4 = widgets.Dropdown(options=sel, value=startset, description='Dataset:', disabled=False)\n",
        "\n",
        "def observe_data_selection_w4_max_corr(*args):\n",
        "  \"\"\"Adjust available voters when changing dataset\"\"\"\n",
        "  dataset = data_selection_w4.value\n",
        "  vmc = cc_dict[dataset].vmc_ranked\n",
        "  thresh_w.max = round(vmc[vmc<1].max().max(), 2)\n",
        "\n",
        "ws_net = [data_selection_w4,net_w,width_w,height_w,thresh_w] #self_corr_w\n",
        "\n",
        "out_net = widgets.interactive_output(display_df_net,{'Dataset':data_selection_w4,'Plot':net_w,'Width':width_w,'Height':height_w,'Thresh':thresh_w,'SelfCorr':self_corr_w})\n",
        "ui_net = widgets.GridBox(ws_net, layout=widgets.Layout(grid_template_columns=\"repeat(2, 400px)\"))\n",
        "\n",
        "display(ui_net, out_net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itdkU3OSHBTz"
      },
      "source": [
        "# Poll Information\n",
        "\n",
        "The \"Diff.\" column in all previous dataframes indicates the difference in ranking between the currently active chart and the default chart.\n",
        "\n",
        "---\n",
        "##### **Film Board Ranks the Decades of Cinema: 2010s**\n",
        "\n",
        "Hosted by diction \n",
        "\n",
        "[RYM List](https://rateyourmusic.com/list/diction/rym-ranks-the-decades-of-cinema-2010s-2021_final-edition/) | [Google Sheet](https://docs.google.com/spreadsheets/d/1zupC7TiE05DorhO7Og2lgCqGw60T-jv9souNf6PlS14/edit?usp=sharing)\n",
        "\n",
        "Started: 12. January 2021<br>\n",
        "Closed: 14. February 2021\n",
        "\n",
        "Default Chart: Classic (Borda count $\\times$ number of votes)\n",
        "\n",
        "I included Decibelle's list this compilation, but not Xetfield's (as it was unlinked). I also updated my own list. :p\n",
        "\n",
        "---\n",
        "##### **Film Board Ranks the Decades of Cinema: 2000s**\n",
        "\n",
        "Hosted by Rengar18\n",
        "\n",
        "[RYM List](https://rateyourmusic.com/list/Rengar18/film-board-ranks-the-decades-of-cinema-2000s/) | [Google Sheet](https://docs.google.com/spreadsheets/d/1n93oIpYzbh7eWmzfR4_BR9nWrciyrIvXP2XiSEWQw-Y/edit?usp=sharing)\n",
        "\n",
        "Started: 28. October 2021<br>\n",
        "Closed: 28. November 2021\n",
        "\n",
        "Default Chart: Classic (Borda count $\\times$ number of votes)\n",
        "\n",
        "---\n",
        "##### **Film Board Ranks the Decades of Cinema: 1990s**\n",
        "\n",
        "Hosted by Rengar18\n",
        "\n",
        "[RYM List](https://rateyourmusic.com/list/Rengar18/film-board-ranks-the-decades-of-cinema-1990s/) | [Google Sheet](https://docs.google.com/spreadsheets/d/1HCwzUm-tGeFFxnbTu5NwXoVKKCyf4p9Di8U1w9hTI1I/edit?usp=sharing)\n",
        "\n",
        "Started: 7. December 2021<br>\n",
        "Closed: 1. February 2022\n",
        "\n",
        "Default Chart: Classic (Borda count $\\times$ number of votes)\n",
        "\n",
        "---\n",
        "##### **Film Board Ranks the Decades of Cinema: 1980s**\n",
        "\n",
        "Hosted by Rengar18\n",
        "\n",
        "[RYM List](https://rateyourmusic.com/list/Rengar18/film-board-ranks-the-decades-of-cinema-1980s/) | [Google Sheet](https://docs.google.com/spreadsheets/d/1tMDLNq7-pJgJe8B5kHB8453KpP4I8_XXHm_tuSml_4Q/edit?usp=sharing)\n",
        "\n",
        "Started: 4. February 2022<br>\n",
        "Closed: 2. May 2022\n",
        "\n",
        "Default Chart: Classic (Borda count $\\times$ number of votes)\n",
        "\n",
        "---\n",
        "##### **Film Board Ranks the Decades of Cinema: 1980s - 2010s**\n",
        "\n",
        "[RYM List](https://rateyourmusic.com/list/YasashiiDia/film-board-esoteric-chart-1980-2019/)\n",
        "\n",
        "The combined results from all decade polls. Note that both the votes and the scores are weighted to adjust for differences in voter turnout between the polls. That is, the votes/scores from the individual decade polls are mutliplied by the following weights:\n",
        "\n",
        "1980s: 1.0<br>\n",
        "1990s: 1.05<br>\n",
        "2000s: 1.38<br>\n",
        "2010s: 2.22<br>\n",
        "\n",
        "Default Chart: Classic (Borda count $\\times$ number of votes)\n",
        "\n",
        "---\n",
        "##### **Top Anime Series as Voted for by RYM**\n",
        "\n",
        "Hosted by YasashiiDia\n",
        "\n",
        "[RYM List](https://rateyourmusic.com/list/YasashiiDia/top-anime-series-as-voted-for-by-rym/) | [Google Sheet](https://docs.google.com/spreadsheets/d/1g2hNzT4EpJj5MZS3-QA4AgsqDzzU-W054FFzkkm-1ds/edit?usp=sharing)\n",
        "\n",
        "Started: 2. February 2019<br>\n",
        "Latest update: 9. August 2021 (open-ended poll)<br>\n",
        "\n",
        "Default Chart: Size-dependent Borda count. Maximum ballot size is 50. Ranked, partially ranked and unranked ballot allowed. For a ballot of length $n$ where the first $m$ elements are ranked, the point distribution for a show in position $p$ is as follows:\n",
        "\n",
        "$\\begin{split}\n",
        "  \\textrm{Points} &= n - p +1 & \\quad \\textrm{for} \\quad p â‰¤ m,\\\\\n",
        "  \\textrm{Points} &= \\frac{1}{2} (n - m + 1) & \\quad \\textrm{for} \\quad p > m\n",
        "\\end{split}$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzp3RA0MIn0f"
      },
      "source": [
        "# Changelog\n",
        "\n",
        "#### Available datasets\n",
        "\n",
        "- 05.05.2022: Film Board Ranks the Decades of Cinema: 1980s\n",
        "- 13.02.2022: Combined Film Chart\n",
        "- 02.02.2022: Film Board Ranks the Decades of Cinema: 1990s\n",
        "- 05.12.2021: Top Anime Series as Voted for by RYM\n",
        "- 05.12.2021: Film Board Ranks the Decades of Cinema: 2010s\n",
        "- 03.12.2021: Film Board Ranks the Decades of Cinema: 2000s\n",
        "\n",
        "#### Features\n",
        "\n",
        "- 05.12.2021: Voter recommendations\n",
        "- 05.12.2021: Multi dataset/poll support\n",
        "- 04.12.2021: Interactive Chart now supports metadata rankings\n",
        "\n",
        "#### Misc. improvements\n",
        "\n",
        "- 02.02.2022: Cast rankings now weighted by top billing\n",
        "- 01.02.2022: Partially ranked ballots now supported\n",
        "- 07.12.2021: Size-dependent Borda Count (for Top Anime Series)\n",
        "- 06.12.2021: Voter correlation with charts\n",
        "- 06.12.2021: First cell now loads all datasets; most other cells should work independently of prior cells once the datasets are loaded\n",
        "- 04.12.2021: Interactive Chart: Pop Weight widget is now disabled when using Classic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go9e0uJG1utX"
      },
      "source": [
        "# To do\n",
        "\n",
        "#### Features\n",
        "\n",
        "- Proper chart display with images\n",
        "\n",
        "- Reset chart button\n",
        "\n",
        "- Save dataframe as image\n",
        "\n",
        "- Weighted rank correlation ([ref](https://cs.uni-paderborn.de/fileadmin/informatik/fg/is/Publications/ECML2015-SG.pdf))\n",
        "\n",
        "- Filter chart by metadata\n",
        "\n",
        "- Sort chart by chosen column\n",
        "\n",
        "- Visualize statistics\n",
        "\n",
        "- Voter recommendations based on custom chart\n",
        "\n",
        "- Voter clustering\n",
        "\n",
        "#### Fixes\n",
        "\n",
        "- Take care of foreign titles with [ when cleaning titles\n",
        "\n",
        "#### Misc. improvements\n",
        "\n",
        "- Correlations etc. for combined film chart\n",
        "\n",
        "- Raw (unnormalized) score for combined film chart\n",
        "\n",
        "- Option to display voters with no connections in the network\n",
        "\n",
        "- Add metadata to voter recommendations\n",
        "\n",
        "- Translate language code\n",
        "\n",
        "- Normalize pop multiplier\n",
        "\n",
        "- Improve metadata rankings dataframe\n",
        "  - Stratify runtime\n",
        "  - Filter by top ranked items\n",
        "  - Add Diff.\n",
        "\n",
        "#### Code improvements\n",
        "\n",
        "- Widget class\n",
        "\n",
        "- Commenting\n",
        "\n",
        "- Generally make code less lousy\n",
        "\n",
        "- Profiling\n",
        "\n",
        "- Make Python package\n",
        "\n",
        "- Automate data git commits"
      ]
    }
  ]
}